{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 42])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mani_skill.envs\n",
    "import gymnasium as gym\n",
    "N = 4\n",
    "env = gym.make(\"PickCube-v1\", num_envs=N)\n",
    "env.action_space # shape (N, D)\n",
    "env.observation_space # shape (N, ...)\n",
    "env.reset()\n",
    "obs, rew, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_once_mean: 0.001953125\n",
      "return_mean: 3.0804972648620605\n",
      "episode_len_mean: 50.0\n",
      "reward_mean: 0.06160994619131088\n",
      "success_at_end_mean: 0.001953125\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "env_id = \"PushCube-v1\"\n",
    "num_eval_envs = 64\n",
    "env_kwargs = dict(obs_mode=\"state\") # modify your env_kwargs here\n",
    "eval_envs = gym.make(env_id, num_envs=num_eval_envs, reconfiguration_freq=1, **env_kwargs)\n",
    "# add any other wrappers here\n",
    "eval_envs = ManiSkillVectorEnv(eval_envs, ignore_terminations=True, record_metrics=True)\n",
    "\n",
    "# evaluation loop, which will record metrics for complete episodes only\n",
    "obs, _ = eval_envs.reset(seed=0)\n",
    "eval_metrics = defaultdict(list)\n",
    "for _ in range(400):\n",
    "    action = eval_envs.action_space.sample() # replace with your policy action\n",
    "    obs, rew, terminated, truncated, info = eval_envs.step(action)\n",
    "    # note as there are no partial resets, truncated is True for all environments at the same time\n",
    "    if truncated.any():\n",
    "        for k, v in info[\"final_info\"][\"episode\"].items():\n",
    "            eval_metrics[k].append(v.float())\n",
    "for k in eval_metrics.keys():\n",
    "    print(f\"{k}_mean: {torch.mean(torch.stack(eval_metrics[k])).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m2025-07-09 09:08:34,636 - mani_skill  - WARNING - mani_skill is not installed with git.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import mani_skill.envs\n",
    "import gymnasium as gym\n",
    "from mani_skill.utils.wrappers.record import RecordEpisode\n",
    "from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "N = 4\n",
    "env = gym.make(\"PickCube-v1\", num_envs=N, render_mode=\"rgb_array\")\n",
    "env = RecordEpisode(env, output_dir=\"videos\", save_trajectory=True, trajectory_name=\"trajectory\", max_steps_per_video=50, video_fps=30)\n",
    "env = ManiSkillVectorEnv(env, auto_reset=True) # adds auto reset\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    obs, reward, terminated, truncated, info = env.step(env.action_space.sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
